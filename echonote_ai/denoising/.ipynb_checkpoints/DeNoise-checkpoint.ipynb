{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1cb850b-5812-4302-b31e-a1fcd053882a",
   "metadata": {},
   "source": [
    "#### j11a210_T 커널로 작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4541851-fcc3-431a-bc19-f55098a6b5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423e6146-c8c9-43cb-8d22-89ead3b7795e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ea6b4ae-2c61-449c-8f33-a167c8ff3454",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: AudioSegment in /home/j-j11a210/.local/lib/python3.10/site-packages (0.23.0)\n",
      "Requirement already satisfied: pydub in /home/j-j11a210/.local/lib/python3.10/site-packages (from AudioSegment) (0.25.1)\n",
      "Requirement already satisfied: webrtcvad in /home/j-j11a210/.local/lib/python3.10/site-packages (from AudioSegment) (2.0.10)\n",
      "Requirement already satisfied: numpy in /opt/tljh/user/lib/python3.10/site-packages (from AudioSegment) (1.26.4)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install AudioSegment\n",
    "!pip install torch torchaudio\n",
    "!pip install deepfilternet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a510aa91-061c-4b4e-a871-c9cdc61ec2f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: torchaudio in /home/j-j11a210/.local/lib/python3.10/site-packages (2.4.1)\n",
      "Requirement already satisfied: torch==2.4.1 in /home/j-j11a210/.local/lib/python3.10/site-packages (from torchaudio) (2.4.1)\n",
      "Requirement already satisfied: filelock in /home/j-j11a210/.local/lib/python3.10/site-packages (from torch==2.4.1->torchaudio) (3.16.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/tljh/user/lib/python3.10/site-packages (from torch==2.4.1->torchaudio) (4.12.2)\n",
      "Requirement already satisfied: sympy in /home/j-j11a210/.local/lib/python3.10/site-packages (from torch==2.4.1->torchaudio) (1.13.2)\n",
      "Requirement already satisfied: networkx in /home/j-j11a210/.local/lib/python3.10/site-packages (from torch==2.4.1->torchaudio) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/tljh/user/lib/python3.10/site-packages (from torch==2.4.1->torchaudio) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/j-j11a210/.local/lib/python3.10/site-packages (from torch==2.4.1->torchaudio) (2024.9.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/j-j11a210/.local/lib/python3.10/site-packages (from torch==2.4.1->torchaudio) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/j-j11a210/.local/lib/python3.10/site-packages (from torch==2.4.1->torchaudio) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/j-j11a210/.local/lib/python3.10/site-packages (from torch==2.4.1->torchaudio) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/j-j11a210/.local/lib/python3.10/site-packages (from torch==2.4.1->torchaudio) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/j-j11a210/.local/lib/python3.10/site-packages (from torch==2.4.1->torchaudio) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/j-j11a210/.local/lib/python3.10/site-packages (from torch==2.4.1->torchaudio) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/j-j11a210/.local/lib/python3.10/site-packages (from torch==2.4.1->torchaudio) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/j-j11a210/.local/lib/python3.10/site-packages (from torch==2.4.1->torchaudio) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/j-j11a210/.local/lib/python3.10/site-packages (from torch==2.4.1->torchaudio) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/j-j11a210/.local/lib/python3.10/site-packages (from torch==2.4.1->torchaudio) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/j-j11a210/.local/lib/python3.10/site-packages (from torch==2.4.1->torchaudio) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /home/j-j11a210/.local/lib/python3.10/site-packages (from torch==2.4.1->torchaudio) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/j-j11a210/.local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.1->torchaudio) (12.6.68)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/tljh/user/lib/python3.10/site-packages (from jinja2->torch==2.4.1->torchaudio) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/j-j11a210/.local/lib/python3.10/site-packages (from sympy->torch==2.4.1->torchaudio) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade torchaudio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d97033e-6760-42b2-bea3-9f2867bf4600",
   "metadata": {},
   "source": [
    "## import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b0894ba-e928-4a1c-8985-3050accc8639",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from df import enhance, init_df\n",
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccaff0af-9cd8-4ad7-ba2a-91f41495e173",
   "metadata": {},
   "source": [
    "## DeNoise 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "88eb211e-84ec-4cb6-bfc4-e98663d68b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-09-24 16:45:21\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mLoading model settings of DeepFilterNet3\u001b[0m\n",
      "\u001b[32m2024-09-24 16:45:21\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mUsing DeepFilterNet3 model at /home/j-j11a210/.cache/DeepFilterNet/DeepFilterNet3\u001b[0m\n",
      "\u001b[32m2024-09-24 16:45:21\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mInitializing model `deepfilternet3`\u001b[0m\n",
      "\u001b[32m2024-09-24 16:45:21\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mFound checkpoint /home/j-j11a210/.cache/DeepFilterNet/DeepFilterNet3/checkpoints/model_120.ckpt.best with epoch 120\u001b[0m\n",
      "\u001b[32m2024-09-24 16:45:21\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mRunning on device cuda:0\u001b[0m\n",
      "\u001b[32m2024-09-24 16:45:21\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mModel loaded\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/j-j11a210/.local/lib/python3.10/site-packages/df/checkpoint.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  latest = torch.load(latest, map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 2.02 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def split_audio(audio_path, segment_length):\n",
    "    # Load audio file\n",
    "    waveform, sample_rate = torchaudio.load(audio_path)\n",
    "    num_samples = waveform.shape[1]\n",
    "    \n",
    "    # Calculate total length in seconds\n",
    "    total_length = num_samples / sample_rate\n",
    "    \n",
    "    # Split the audio into segments\n",
    "    segments = []\n",
    "    for start in range(0, int(total_length), segment_length):\n",
    "        end = min(start + segment_length, int(total_length))\n",
    "        start_sample = start * sample_rate\n",
    "        end_sample = end * sample_rate\n",
    "        segments.append(waveform[:, start_sample:end_sample])\n",
    "    \n",
    "    return segments, sample_rate\n",
    "\n",
    "def enhance_audio(segments, model, df_state):\n",
    "    enhanced_segments = []\n",
    "    for segment in segments:\n",
    "        # Convert segment to mono if needed\n",
    "        segment = segment.mean(dim=0).unsqueeze(0)  # Convert to mono\n",
    "        # Apply noise reduction\n",
    "        enhanced_segment = enhance(model, df_state, segment)\n",
    "        enhanced_segments.append(enhanced_segment)\n",
    "    return enhanced_segments\n",
    "\n",
    "def combine_audio(segments):\n",
    "    return torch.cat(segments, dim=1)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Initialize the DeepFilterNet model\n",
    "model, df_state, _ = init_df()\n",
    "\n",
    "original = \"../testAudio/noNoise_codeapple.wav\"\n",
    "# no_noise = \"noNoise.wav\"\n",
    "\n",
    "# 노이즈가 포함된 오디오 파일 로드\n",
    "noisy_audio_path = original\n",
    "waveform, sample_rate = torchaudio.load(noisy_audio_path)\n",
    "segment_length = 10 * 60  # 10 minutes in seconds\n",
    "\n",
    "\n",
    "# 오디오를 단일 채널로 변환하고 필요한 경우 차원을 추가하여 형식 조정\n",
    "waveform = waveform.mean(dim=0).unsqueeze(0)  # 모노로 변환\n",
    "\n",
    "# 오디오 향상\n",
    "# Step 1: Split audio\n",
    "audio_segments, sample_rate = split_audio(original, segment_length)\n",
    "\n",
    "# Step 2: Enhance audio\n",
    "enhanced_segments = enhance_audio(audio_segments, model, df_state)\n",
    "\n",
    "# Step 3: Combine audio\n",
    "combined_audio = combine_audio(enhanced_segments)\n",
    "\n",
    "# 노이즈 제거된 음원 저장\n",
    "# torchaudio.save(no_noise, enhanced_waveform, sample_rate)\n",
    "\n",
    "end_time = time.time() - start_time\n",
    "\n",
    "print(f\"Time: {end_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cb47c952-a140-4e54-a3c0-67b6cf0e84a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torchaudio.save(\"no_noise.wav\", combined_audio, sample_rate) # 저장 코드\n",
    "torch.cuda.empty_cache() # 캐시 메모리 삭제하고 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e535349a-88ed-4d5d-91d4-8aa59599ed14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_averages(segments):\n",
    "    # 초기값 설정\n",
    "    total_temperature = 0\n",
    "    total_avg_logprob = 0\n",
    "    total_compression_ratio = 0\n",
    "    total_no_speech_prob = 0\n",
    "    segment_count = len(segments)\n",
    "    \n",
    "    # 각 segment에서 값 추출 및 합산\n",
    "    for segment in segments:\n",
    "        total_temperature += segment.get('temperature', 0)\n",
    "        total_avg_logprob += segment.get('avg_logprob', 0)\n",
    "        total_compression_ratio += segment.get('compression_ratio', 0)\n",
    "        total_no_speech_prob += segment.get('no_speech_prob', 0)\n",
    "    \n",
    "    # 평균 계산\n",
    "    avg_temperature = total_temperature / segment_count if segment_count > 0 else 0\n",
    "    avg_avg_logprob = total_avg_logprob / segment_count if segment_count > 0 else 0\n",
    "    avg_compression_ratio = total_compression_ratio / segment_count if segment_count > 0 else 0\n",
    "    avg_no_speech_prob = total_no_speech_prob / segment_count if segment_count > 0 else 0\n",
    "    \n",
    "    # 결과 출력\n",
    "    print(f\"Average Temperature: {avg_temperature}\")\n",
    "    print(f\"Average Avg Log Probability: {avg_avg_logprob}\")\n",
    "    print(f\"Average Compression Ratio: {avg_compression_ratio}\")\n",
    "    print(f\"Average No Speech Probability: {avg_no_speech_prob}\")\n",
    "    \n",
    "    return {\n",
    "        'avg_temperature': avg_temperature,\n",
    "        'avg_avg_logprob': avg_avg_logprob,\n",
    "        'avg_compression_ratio': avg_compression_ratio,\n",
    "        'avg_no_speech_prob': avg_no_speech_prob\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "daa2998c-77d4-43c3-a119-44d95ed0d416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Temperature: 0.07475035663338102\n",
      "Average Avg Log Probability: -0.3330184866026178\n",
      "Average Compression Ratio: 1.7180050845319825\n",
      "Average No Speech Probability: 0.028729856795166434\n",
      "\n",
      "Average Temperature: 0.08983174835406013\n",
      "Average Avg Log Probability: -0.2823926059229339\n",
      "Average Compression Ratio: 1.6912596886977687\n",
      "Average No Speech Probability: 0.05061596407052112\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 평균 계산\n",
    "averages = calculate_averages(no_Noise_result['segments'])\n",
    "print(\"\")\n",
    "averages = calculate_averages(result['segments'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
