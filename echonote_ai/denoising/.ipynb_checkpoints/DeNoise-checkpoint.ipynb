{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "#### j11a210_T 커널로 작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install AudioSegment\n",
    "!pip install torch torchaudio\n",
    "!pip install deepfilternet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade torchaudio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from df import enhance, init_df\n",
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## DeNoise 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def split_audio(audio_path, segment_length):\n",
    "    # Load audio file\n",
    "    waveform, sample_rate = torchaudio.load(audio_path)\n",
    "    num_samples = waveform.shape[1]\n",
    "    \n",
    "    # Calculate total length in seconds\n",
    "    total_length = num_samples / sample_rate\n",
    "    \n",
    "    # Split the audio into segments\n",
    "    segments = []\n",
    "    for start in range(0, int(total_length), segment_length):\n",
    "        end = min(start + segment_length, int(total_length))\n",
    "        start_sample = start * sample_rate\n",
    "        end_sample = end * sample_rate\n",
    "        segments.append(waveform[:, start_sample:end_sample])\n",
    "    \n",
    "    return segments, sample_rate\n",
    "\n",
    "def enhance_audio(segments, model, df_state):\n",
    "    enhanced_segments = []\n",
    "    for segment in segments:\n",
    "        # Convert segment to mono if needed\n",
    "        segment = segment.mean(dim=0).unsqueeze(0)  # Convert to mono\n",
    "        # Apply noise reduction\n",
    "        enhanced_segment = enhance(model, df_state, segment)\n",
    "        enhanced_segments.append(enhanced_segment)\n",
    "    return enhanced_segments\n",
    "\n",
    "def combine_audio(segments):\n",
    "    return torch.cat(segments, dim=1)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Initialize the DeepFilterNet model\n",
    "model, df_state, _ = init_df()\n",
    "\n",
    "original = \"../testAudio/noNoise_codeapple.wav\"\n",
    "# no_noise = \"noNoise.wav\"\n",
    "\n",
    "# 노이즈가 포함된 오디오 파일 로드\n",
    "noisy_audio_path = original\n",
    "waveform, sample_rate = torchaudio.load(noisy_audio_path)\n",
    "segment_length = 10 * 60  # 10 minutes in seconds\n",
    "\n",
    "\n",
    "# 오디오를 단일 채널로 변환하고 필요한 경우 차원을 추가하여 형식 조정\n",
    "waveform = waveform.mean(dim=0).unsqueeze(0)  # 모노로 변환\n",
    "\n",
    "# 오디오 향상\n",
    "# Step 1: Split audio\n",
    "audio_segments, sample_rate = split_audio(original, segment_length)\n",
    "\n",
    "# Step 2: Enhance audio\n",
    "enhanced_segments = enhance_audio(audio_segments, model, df_state)\n",
    "\n",
    "# Step 3: Combine audio\n",
    "combined_audio = combine_audio(enhanced_segments)\n",
    "\n",
    "# 노이즈 제거된 음원 저장\n",
    "# torchaudio.save(no_noise, enhanced_waveform, sample_rate)\n",
    "\n",
    "end_time = time.time() - start_time\n",
    "\n",
    "print(f\"Time: {end_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torchaudio.save(\"no_noise.wav\", combined_audio, sample_rate) # 저장 코드\n",
    "torch.cuda.empty_cache() # 캐시 메모리 삭제하고 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_averages(segments):\n",
    "    # 초기값 설정\n",
    "    total_temperature = 0\n",
    "    total_avg_logprob = 0\n",
    "    total_compression_ratio = 0\n",
    "    total_no_speech_prob = 0\n",
    "    segment_count = len(segments)\n",
    "    \n",
    "    # 각 segment에서 값 추출 및 합산\n",
    "    for segment in segments:\n",
    "        total_temperature += segment.get('temperature', 0)\n",
    "        total_avg_logprob += segment.get('avg_logprob', 0)\n",
    "        total_compression_ratio += segment.get('compression_ratio', 0)\n",
    "        total_no_speech_prob += segment.get('no_speech_prob', 0)\n",
    "    \n",
    "    # 평균 계산\n",
    "    avg_temperature = total_temperature / segment_count if segment_count > 0 else 0\n",
    "    avg_avg_logprob = total_avg_logprob / segment_count if segment_count > 0 else 0\n",
    "    avg_compression_ratio = total_compression_ratio / segment_count if segment_count > 0 else 0\n",
    "    avg_no_speech_prob = total_no_speech_prob / segment_count if segment_count > 0 else 0\n",
    "    \n",
    "    # 결과 출력\n",
    "    print(f\"Average Temperature: {avg_temperature}\")\n",
    "    print(f\"Average Avg Log Probability: {avg_avg_logprob}\")\n",
    "    print(f\"Average Compression Ratio: {avg_compression_ratio}\")\n",
    "    print(f\"Average No Speech Probability: {avg_no_speech_prob}\")\n",
    "    \n",
    "    return {\n",
    "        'avg_temperature': avg_temperature,\n",
    "        'avg_avg_logprob': avg_avg_logprob,\n",
    "        'avg_compression_ratio': avg_compression_ratio,\n",
    "        'avg_no_speech_prob': avg_no_speech_prob\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 평균 계산\n",
    "averages = calculate_averages(no_Noise_result['segments'])\n",
    "print(\"\")\n",
    "averages = calculate_averages(result['segments'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
